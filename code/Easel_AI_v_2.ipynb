{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLzkKhx85HuY"
      },
      "source": [
        "# Easel AI: Founding AI Engineer | Thumbs Up Challenge\n",
        "\n",
        "Author: Sukruth Gowdru Lingaraju.  \n",
        "Email: [sg2257@cornell.edu](mailto:sg2257@cornell.edu).  \n",
        "September 5th, 2023\n",
        "\n",
        "This notebook performs fine-tuning on the baseline [runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5) stable diffusion model based on a custom dataset - [glsukki/thumbs_up_v2](https://huggingface.co/datasets/glsukki/thumbs_up_v2) - to generate images for the prompt style `<person><trigger_word>`.  \n",
        "\n",
        "NOTE: To successfully run and train the model on the custom dataset, connect to a GPU having a runtime memory ` >= 30 GB`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vouHyZKHHpVO"
      },
      "source": [
        "## Install dependencies and library requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H60WRP9GkF03"
      },
      "outputs": [],
      "source": [
        "!cd /content/\n",
        "!git clone https://github.com/huggingface/diffusers.git\n",
        "!pip install ./diffusers\n",
        "!pip install -U -r /content/diffusers/examples/text_to_image/requirements.txt\n",
        "!pip install tensorboard==2.12.3\n",
        "!pip install wandb\n",
        "!pip install -U torchmetrics\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from functools import partial\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from torchmetrics.functional.multimodal import clip_score\n",
        "\n",
        "seed = random.randint(1, 999999)\n",
        "generator = torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHVsUr5IzsdY"
      },
      "outputs": [],
      "source": [
        "# GPU Compute check\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "702rJju4vltp"
      },
      "source": [
        "# Set Environment variables\n",
        "\n",
        "MODEL_NAME: refers to the baseline model being imported for fine-tuning on the custom dataset.  \n",
        "DATASET_NAME: refers to the custom dataset used for fine-tuning.  \n",
        "OUTPUT_DIR: refers to the name of the fine-tuned model pushed to HuggingFace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoEDHR8VKj6a"
      },
      "outputs": [],
      "source": [
        "os.environ['MODEL_NAME'] = f'runwayml/stable-diffusion-v1-5'\n",
        "os.environ['DATASET_NAME'] = f'glsukki/thumbs_up_test_2'\n",
        "os.environ['OUTPUT_DIR'] = f'stable-diffusion-thumbs-up-8000_1e-05'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PV8oFXh3Mgri"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcT99uN5Kuom"
      },
      "source": [
        "### Thumbs_Up Stable Diffusion Model\n",
        "\n",
        "#### Dataset\n",
        "\n",
        "Custom dataset consisting of ```glsukki/thumbs_up```'s dataset on HuggingFace which consists of\n",
        "*   ```thumbs up``` images from [LINK](https://www.dropbox.com/s/xtspymftfmjofo6/thumbs-up.zip?dl=0)\n",
        "  *   ```# of images = 121```\n",
        "  *   ```type: JPEG```\n",
        "  *   ```shape: 512x512```\n",
        "*   ```person: sukruth``` custom images\n",
        "  *   ```# of images = 336```\n",
        "  *   ```type: JPEG```\n",
        "  *   ```shape: 512x512```\n",
        "\n",
        "We fine-tune the ```runwayml/stable-diffusion-v1-5``` model by feeding the ```glsukki/thumbs_up_v2``` dataset as the input for training on-top of the base-model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MF55kLYEZPdx"
      },
      "outputs": [],
      "source": [
        "!accelerate config default --mixed_precision fp16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5DDm_Gi3LM8P"
      },
      "outputs": [],
      "source": [
        "!accelerate launch diffusers/examples/text_to_image/train_text_to_image.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --dataset_name=$DATASET_NAME \\\n",
        "  --use_ema \\\n",
        "  --resolution=512 --center_crop --random_flip \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=4 \\\n",
        "  --gradient_checkpointing \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --max_train_steps=8000 \\\n",
        "  --learning_rate=1e-05 \\\n",
        "  --max_grad_norm=1 \\\n",
        "  --validation_prompt='sukruth thumbs up' \\\n",
        "  --push_to_hub \\\n",
        "  --checkpointing_steps=100000 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --output_dir=$OUTPUT_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0noE1OQhWV71"
      },
      "source": [
        "### Load the fine-tuned trained model and generate the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yzIMtfkMf9P"
      },
      "outputs": [],
      "source": [
        "# thumbs_up_model_id = './stable-diffusion-thumbs-up-8000_1e-05' # for faster model load time if the model is present locally\n",
        "thumbs_up_model_id = 'glsukki/stable-diffusion-thumbs-up-8000_1e-05'\n",
        "thumbs_up_pipe = StableDiffusionPipeline.from_pretrained(thumbs_up_model_id, torch_dtype=torch.float16)\n",
        "thumbs_up_pipe = thumbs_up_pipe.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-vBqvhKLBU4"
      },
      "source": [
        "### Model Evaluation\n",
        "\n",
        "Evaluation Metric: ```CLIP Score```\n",
        "\n",
        "Used to measure the compatibility/similarity between the SD generated image to its corresponding caption/prompt pair."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kqYiqwNLAQr"
      },
      "outputs": [],
      "source": [
        "clip_score_fn = partial(clip_score, model_name_or_path=\"openai/clip-vit-base-patch16\")\n",
        "\n",
        "## Calculate the similarity score and return the value\n",
        "## Higher the score, closer similarity of the image to the prompt given\n",
        "def calculate_clip_score(images, prompts):\n",
        "    images_int = (images * 255).astype(\"uint8\")\n",
        "    if len(prompts) == 1:\n",
        "        images_int = np.expand_dims(images_int, axis=0)  # Add a batch dimension\n",
        "    clip_score = clip_score_fn(torch.from_numpy(images_int).permute(0, 3, 1, 2), prompts).detach()\n",
        "    return round(float(clip_score), 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0z1vckiKkAc"
      },
      "source": [
        "### Image Generation\n",
        "\n",
        "Define the prompt(s) on which the image has to be based on and generated by the fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAhydsr_GyF8"
      },
      "outputs": [],
      "source": [
        "# A list of 25 prompts containing <person_name> followed by <trigger_word>\n",
        "# Here, the keyword's values are as follows:\n",
        "# - <person_name> : 'sukruth'\n",
        "# - <trigger_word> : 'thumbs up'\n",
        "\n",
        "diff_prompts = [\n",
        "    \"Sukruth giving a thumbs up at a sunny beach.\",\n",
        "    \"Sukruth enthusiastically showing a thumbs up in a bustling city.\",\n",
        "    \"Sukruth flashing a thumbs up sign while hiking in the mountains.\",\n",
        "    \"Sukruth smiling and giving a thumbs up in a cozy coffee shop.\",\n",
        "    \"Sukruth offering a thumbs up gesture at a lively music festival.\",\n",
        "    \"Sukruth expressing approval with a thumbs up on a snowy mountain peak.\",\n",
        "    \"Sukruth presenting a confident thumbs up in a modern office.\",\n",
        "    \"Sukruth happily giving a thumbs up while cooking in the kitchen.\",\n",
        "    \"Sukruth giving a thumbs up during an intense workout at the gym.\",\n",
        "    \"Sukruth showing a thumbs up while exploring a lush forest.\",\n",
        "    \"Sukruth delivering a thumbs up during a thrilling roller coaster ride.\",\n",
        "    \"Sukruth flashing a thumbs up on a serene lakeside dock.\",\n",
        "    \"Sukruth enthusiastically giving a thumbs up on a skateboard.\",\n",
        "    \"Sukruth expressing approval with a thumbs up at an art gallery.\",\n",
        "    \"Sukruth smiling and showing a thumbs up at a rooftop party.\",\n",
        "    \"Sukruth offering a thumbs up sign while on a hot air balloon ride.\",\n",
        "    \"Sukruth confidently giving a thumbs up at a technology conference.\",\n",
        "    \"Sukruth giving a thumbs up during a fun-filled family picnic.\",\n",
        "    \"Sukruth flashing a thumbs up while exploring an ancient temple.\",\n",
        "    \"Sukruth happily showing a thumbs up on a colorful carnival ride.\",\n",
        "    \"Sukruth expressing approval with a thumbs up at a bustling market.\",\n",
        "    \"Sukruth smiling and giving a thumbs up on a scenic road trip.\",\n",
        "    \"Sukruth offering a thumbs up sign during a karaoke night.\",\n",
        "    \"Sukruth confidently giving a thumbs up at a sports stadium.\",\n",
        "    \"Sukruth giving a thumbs up while enjoying a picnic in the park.\"\n",
        "]\n",
        "\n",
        "same_prompt = ['sukruth thumbs up']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbdewRpVteOM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def generateImages(prompts, model_version):\n",
        "  # # Display the images generated by the prompts in an Image Grid\n",
        "  num_rows = 5\n",
        "  num_cols = 5\n",
        "  sd_image, axs = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
        "  sd_image.tight_layout()\n",
        "\n",
        "  image_directory = f'./sd_{model_version}'\n",
        "\n",
        "  if not os.path.exists(image_directory):\n",
        "    os.mkdir(image_directory)\n",
        "\n",
        "  if len(prompts) == 1:\n",
        "    for prompt in range(25):\n",
        "      row_idx = prompt // num_cols\n",
        "      col_idx = prompt % num_cols\n",
        "\n",
        "      generator_1 = torch.manual_seed(random.randint(1, 99999))\n",
        "      image = thumbs_up_pipe(prompts[0], generator = generator_1).images[0]\n",
        "      image.save(f'./{image_directory}/prompt_{prompt + 1}.png')\n",
        "\n",
        "      # # Calculate the CLIP score for the same image\n",
        "      np_image = thumbs_up_pipe(prompts[0], generator = generator_1, output_type=\"numpy\").images[0]\n",
        "      sd_clip_score = calculate_clip_score(np_image, [prompts[0]])\n",
        "      # print(f\"CLIP score: {sd_clip_score}\")\n",
        "\n",
        "      ax = axs[row_idx, col_idx]\n",
        "      ax.imshow(image)\n",
        "      ax.set_title(f'Prompt {prompt + 1}\\'s Image \\nCLIP Score = {sd_clip_score}')\n",
        "      ax.axis('off')\n",
        "  else:\n",
        "    # # Iterate over all the prompts, and generate the image respectively\n",
        "    # # Once the image is generated, save it to file locally and add it as a subplot to the Prompt Image's grid\n",
        "    for prompt in range(len(prompts)):\n",
        "\n",
        "      row_idx = prompt // num_cols\n",
        "      col_idx = prompt % num_cols\n",
        "\n",
        "      image = thumbs_up_pipe(prompts[prompt], generator = generator).images[0]\n",
        "      image.save(f'./{image_directory}/prompt_{prompt + 1}.png')\n",
        "\n",
        "      # # Calculate the CLIP score for the same image\n",
        "      np_image = thumbs_up_pipe(prompts[prompt], generator = generator, output_type=\"numpy\").images[0]\n",
        "      sd_clip_score = calculate_clip_score(np_image, [prompts[prompt]])\n",
        "      # print(f\"CLIP score: {sd_clip_score}\")\n",
        "\n",
        "      ax = axs[row_idx, col_idx]\n",
        "      ax.imshow(image)\n",
        "      ax.set_title(f'Prompt {prompt + 1}\\'s Image \\nCLIP Score = {sd_clip_score}')\n",
        "      ax.axis('off')\n",
        "\n",
        "  plt.show()\n",
        "  sd_image.savefig(f'./{image_directory}/{model_version}_prompts.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmmBGkMStfQC"
      },
      "outputs": [],
      "source": [
        "# for different prompts\n",
        "diff_model_name = '8000_121_336_diff'\n",
        "generateImages(diff_prompts, diff_model_name)\n",
        "\n",
        "# for same prompts\n",
        "same_model_name = '8000_121_336_same'\n",
        "generateImages(same_prompt, same_model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW_KsttzJ8bA"
      },
      "source": [
        "### Baseline Model Inference : ```runwayml/stable-diffusion-v1-5```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYJYILFyMTrt"
      },
      "outputs": [],
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "import random\n",
        "\n",
        "generator = torch.manual_seed(random.randint(1, 9999))\n",
        "\n",
        "base_model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "base_pipe = StableDiffusionPipeline.from_pretrained(base_model_id, torch_dtype=torch.float16)\n",
        "base_pipe = base_pipe.to(\"cuda\")\n",
        "\n",
        "base_prompt = [\"sukruth thumbs up\"]\n",
        "PIL_image = base_pipe(base_prompt, generator = generator).images[0]\n",
        "image = base_pipe(base_prompt, generator = generator, output_type='numpy').images[0]\n",
        "\n",
        "PIL_image.save(\"./base_model_prompt_1.png\")\n",
        "\n",
        "## Check the similarity score for the image generated by the baseline model to the corresponding prompt\n",
        "sd_clip_score = calculate_clip_score(image, base_prompt)\n",
        "print(f\"CLIP score: {sd_clip_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4H9mfRM9t9__"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}